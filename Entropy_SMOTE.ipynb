{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritam-banik-roy/Software_Defect_Prediction/blob/main/Entropy_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVjGlffZMpBj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_validate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMomKp6Lav-m",
        "outputId": "04f43147-af12-44e0-e860-397598f0dff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "id": "jzCVmNokOUTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_norm_data(path):\n",
        "    #df = pd.read_csv(path, header=None)\n",
        "    df = pd.read_csv(path)\n",
        "    data = df.values\n",
        "    label = data[:, -1]\n",
        "    columns = data.shape[1]\n",
        "    x = data[:, :columns - 1]\n",
        "\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    x = min_max_scaler.fit_transform(x)\n",
        "\n",
        "    Maj_num = Counter(label)[0]\n",
        "    Min_num = Counter(label)[1]\n",
        "    IR = Maj_num / Min_num\n",
        "\n",
        "    print(\"Instances: {0} ,Features: {1} ,Maj: {2} ,Min: {3} ,IR: {4} \".format(len(label), columns - 1, Maj_num,\n",
        "                                                                               Min_num,\n",
        "                                                                               round(IR, 2)))\n",
        "    return x, label, Maj_num, Min_num, round(IR, 2), columns - 1\n",
        "\n"
      ],
      "metadata": {
        "id": "aQRJ1InwM_2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entropy(labels, base=None):\n",
        "  value,counts = np.unique(labels, return_counts=True)\n",
        "  return entropy(counts, base=base)"
      ],
      "metadata": {
        "id": "p5DacbnwQ7ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy_smote(X,y,n_clus = 5,entropy_threshold = 0.2):\n",
        "  # Find clusters\n",
        "  kmeans = KMeans(n_clusters=n_clus, random_state=0).fit(X)\n",
        "  select_data_index = []\n",
        "\n",
        "  # Find entropy for every cluster\n",
        "\n",
        "  for cluster in range(n_clus):\n",
        "\n",
        "    # Find index of data points which belongs to a particular cluster\n",
        "\n",
        "    cluster_index = np.where(kmeans.labels_ == cluster)[0]\n",
        "\n",
        "    # Calculate Entropy of that cluster\n",
        "\n",
        "    cluster_entropy = get_entropy(y[cluster_index])\n",
        "\n",
        "    # If entropy is less than threshold that means its purer\n",
        "    # then add index values to select data pool\n",
        "\n",
        "    if cluster_entropy <= entropy_threshold:\n",
        "      select_data_index.extend(cluster_index)\n",
        "\n",
        "  # Find index of minority samples from selected data\n",
        "  min_sample_index = []\n",
        "  for id in select_data_index:\n",
        "    if y[id] == 1:\n",
        "      min_sample_index.append(id)\n",
        "\n",
        "  # Following not working as y[select_data_index] is resetting index values\n",
        "  # min_sample_index = np.where(y[select_data_index] == 1)[0]\n",
        "\n",
        "  min_sample_index = np.array(min_sample_index)\n",
        "  print('No. of minority samples selected: ',min_sample_index.shape[0])\n",
        "\n",
        "  # Resample the minority data samples whose index values are stored in min_sample_index\n",
        "\n",
        "  majority_data_index = np.where(y == 0)[0]\n",
        "  X_maj = X[majority_data_index,:]\n",
        "  y_maj = y[majority_data_index]\n",
        "  X = np.vstack((X_maj,X[min_sample_index,:]))\n",
        "  y = np.hstack((y_maj,y[min_sample_index]))\n",
        "  #print(\"y_maj:{}, y_min_select:{}, X:{}, y:{}, y_count: {}, y_maj_count:{}, y_min_count:{}\".format(y_maj.shape[0], min_sample_index.shape[0], X.shape[0], y.shape[0], Counter(y),Counter(y_maj),Counter(y[min_sample_index])))\n",
        "  X_resampled, y_resampled = SMOTE(sampling_strategy = 'minority').fit_resample(X, y)\n",
        "\n",
        "  return X_resampled, y_resampled"
      ],
      "metadata": {
        "id": "aWprxKe8NI0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/drive/MyDrive/imbalanced_datasets/ecoli1.csv'\n",
        "X, y, Maj_num, Min_num, IR, features = load_norm_data(path)\n",
        "X_resampled, y_resampled = entropy_smote(X,y,entropy_threshold=0.18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-IHoEdPEjy",
        "outputId": "13039c7f-f894-4da7-e774-cce53b3a89fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instances: 336 ,Features: 7 ,Maj: 259 ,Min: 77 ,IR: 3.36 \n",
            "No. of minority samples selected:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resampled dataset shape %s' % Counter(y))\n",
        "print('Resampled dataset shape %s' % Counter(y_resampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZKI2NS66xrg",
        "outputId": "e71450d2-8148-4226-e4ca-023d75ad33cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({0.0: 259, 1.0: 77})\n",
            "Resampled dataset shape Counter({0.0: 259, 1.0: 259})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "scores = cross_validate(clf, X, y, cv=5, scoring='f1_macro')\n",
        "print(\"Before Resampling: %0.2f (%0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std()))\n",
        "X_smote, y_smote = SMOTE(sampling_strategy = 'minority').fit_resample(X, y)\n",
        "scores = cross_validate(clf, X, y, cv=5, scoring='f1_macro')\n",
        "print(\"After SMOTE: %0.2f (%0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std()))\n",
        "scores = cross_validate(clf, X, y, cv=5, scoring='f1_macro')\n",
        "print(\"After ESMOTE: %0.2f (%0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J084dWGucOj9",
        "outputId": "13516ec9-238c-48bc-c2ea-bb17664dd427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Resampling: 0.79 (0.14)\n",
            "After SMOTE: 0.79 (0.14)\n",
            "After ESMOTE: 0.79 (0.14)\n"
          ]
        }
      ]
    }
  ]
}