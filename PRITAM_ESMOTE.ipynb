{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritam-banik-roy/Software_Defect_Prediction/blob/main/PRITAM_ESMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNVTFKIWr7n4",
        "outputId": "cb37ffae-ecad-436b-97f9-ecf4cda6fa38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gLKn9KrsD9O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfnytV8lsIDE"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zN5_Kl5sL9s"
      },
      "outputs": [],
      "source": [
        "def load_norm_data(path):\n",
        "    #df = pd.read_csv(path, header=None)\n",
        "    df = pd.read_csv(path)\n",
        "    data = df.values\n",
        "    label = data[:, -1]\n",
        "    columns = data.shape[1]\n",
        "    x = data[:, :columns - 1]\n",
        "\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    x = min_max_scaler.fit_transform(x)\n",
        "\n",
        "    Maj_num = Counter(label)[0]\n",
        "    Min_num = Counter(label)[1]\n",
        "    IR = Maj_num / Min_num\n",
        "\n",
        "    print(\"Instances: {0} ,Features: {1} ,Maj: {2} ,Min: {3} ,IR: {4} \".format(len(label), columns - 1, Maj_num,\n",
        "                                                                               Min_num,\n",
        "                                                                               round(IR, 2)))\n",
        "    return x, label, Maj_num, Min_num, round(IR, 2), columns - 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB9REPgnsQeq"
      },
      "outputs": [],
      "source": [
        "def get_entropy(labels, base=None):\n",
        "  value,counts = np.unique(labels, return_counts=True)\n",
        "  return entropy(counts, base=base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLJZ3WNOsX2s"
      },
      "outputs": [],
      "source": [
        "def entropy_smote(X,y,n_clus = 5,entropy_threshold = 0.2):\n",
        "  # Find clusters\n",
        "  kmeans = KMeans(n_clusters=n_clus, random_state=0).fit(X)\n",
        "  select_data_index = []\n",
        "\n",
        "  # Find entropy for every cluster\n",
        "\n",
        "  for cluster in range(n_clus):\n",
        "\n",
        "    # Find index of data points which belongs to a particular cluster\n",
        "\n",
        "    cluster_index = np.where(kmeans.labels_ == cluster)[0]\n",
        "\n",
        "    # Calculate Entropy of that cluster\n",
        "\n",
        "    cluster_entropy = get_entropy(y[cluster_index])\n",
        "\n",
        "    # If entropy is less than threshold that means its purer\n",
        "    # then add index values to select data pool\n",
        "\n",
        "    if cluster_entropy <= entropy_threshold:\n",
        "      select_data_index.extend(cluster_index)\n",
        "\n",
        "  # Find index of minority samples from selected data\n",
        "  min_sample_index = []\n",
        "  for id in select_data_index:\n",
        "    if y[id] == 1:\n",
        "      min_sample_index.append(id)\n",
        "\n",
        "  # Following not working as y[select_data_index] is resetting index values\n",
        "  # min_sample_index = np.where(y[select_data_index] == 1)[0]\n",
        "\n",
        "  min_sample_index = np.array(min_sample_index)\n",
        "  print('No. of minority samples selected: ',min_sample_index.shape[0])\n",
        "\n",
        "  # Resample the minority data samples whose index values are stored in min_sample_index\n",
        "\n",
        "  majority_data_index = np.where(y == 0)[0]\n",
        "  X_maj = X[majority_data_index,:]\n",
        "  y_maj = y[majority_data_index]\n",
        "  X = np.vstack((X_maj,X[min_sample_index,:]))\n",
        "  y = np.hstack((y_maj,y[min_sample_index]))\n",
        "  #print(\"y_maj:{}, y_min_select:{}, X:{}, y:{}, y_count: {}, y_maj_count:{}, y_min_count:{}\".format(y_maj.shape[0], min_sample_index.shape[0], X.shape[0], y.shape[0], Counter(y),Counter(y_maj),Counter(y[min_sample_index])))\n",
        "  X_resampled, y_resampled = SMOTE(sampling_strategy = 'minority').fit_resample(X, y)\n",
        "\n",
        "  return X_resampled, y_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMVDNPUQtZLt"
      },
      "outputs": [],
      "source": [
        "path = r'/content/cm1.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mD20Amisg1g",
        "outputId": "e3df3498-6ad8-402d-ef96-d86f3bb1cf8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instances: 498 ,Features: 21 ,Maj: 449 ,Min: 49 ,IR: 9.16 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of minority samples selected:  21\n"
          ]
        }
      ],
      "source": [
        "X, y, Maj_num, Min_num, IR, features = load_norm_data(path)\n",
        "X_resampled, y_resampled = entropy_smote(X,y,entropy_threshold=0.27)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Resampled dataset shape %s' % Counter(y))\n",
        "print('Resampled dataset shape %s' % Counter(y_resampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Vv1HQSsjSO",
        "outputId": "0cf169da-7690-426a-8030-7ee2451d6458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled dataset shape Counter({0.0: 449, 1.0: 49})\n",
            "Resampled dataset shape Counter({0.0: 449, 1.0: 449})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create an SVM classifier with linear kernel\n",
        "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "\n",
        "# Perform cross-validation without resampling\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(\"Before Resampling: %0.2f (%0.2f)\" % (scores.mean(), scores.std()))\n",
        "\n",
        "# Perform SMOTE resampling\n",
        "X_smote, y_smote = SMOTE(sampling_strategy='minority').fit_resample(X, y)\n",
        "\n",
        "# Perform cross-validation after SMOTE resampling\n",
        "scores = cross_val_score(clf, X_smote, y_smote, cv=5)\n",
        "print(\"After SMOTE: %0.2f (%0.2f)\" % (scores.mean(), scores.std()))\n",
        "\n",
        "# Perform E-SMOTE resampling (assuming you have previously defined X_resampled and y_resampled)\n",
        "scores = cross_val_score(clf, X_resampled, y_resampled, cv=5)\n",
        "print(\"After E-SMOTE: %0.2f (%0.2f)\" % (scores.mean(), scores.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtRc7qYu34D2",
        "outputId": "a925e114-6177-4b9b-fc25-1e2a42fa4ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Resampling: 0.90 (0.00)\n",
            "After SMOTE: 0.77 (0.04)\n",
            "After E-SMOTE: 0.66 (0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=5)\n",
        "print(\"Before Resampling: %0.2f (%0.2f)\" % (scores.mean(), scores.std()))\n",
        "X_smote, y_smote = SMOTE(sampling_strategy = 'minority').fit_resample(X, y)\n",
        "scores = cross_val_score(clf, X_smote, y_smote, cv=5)\n",
        "print(\"After SMOTE: %0.2f (%0.2f)\" % (scores.mean(), scores.std()))\n",
        "scores = cross_val_score(clf, X_resampled, y_resampled, cv=5)\n",
        "print(\"After ESMOTE: %0.2f (%0.2f)\" % (scores.mean(), scores.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxzLjfbozIO3",
        "outputId": "a52d443c-662d-427b-b428-fb52f7cbb3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Resampling: 0.90 (0.00)\n",
            "After SMOTE: 0.75 (0.04)\n",
            "After ESMOTE: 0.66 (0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**"
      ],
      "metadata": {
        "id": "rAXoZ-PV4HHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "svm_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Predict on the original test set\n",
        "y_pred = svm_model.predict(X_resampled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTmElNWTzg4o",
        "outputId": "d502e7c3-ac0f-40c1-9dca-e0f2dd88a673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.678173719376392\n",
            "Precision: 0.6120448179271709\n",
            "Recall: 0.9732739420935412\n",
            "G-Mean: 0.6144808128913708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DT**"
      ],
      "metadata": {
        "id": "DfWlFotC4K3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Predict on the original test set\n",
        "y_pred = dt_model.predict(X_resampled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-mean:\", g_mean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZA6OayIzwyy",
        "outputId": "ebf185bc-9608-44e4-da80-67e131683b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9988864142538976\n",
            "Precision: 1.0\n",
            "Recall: 0.9977728285077951\n",
            "G-mean: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN**"
      ],
      "metadata": {
        "id": "wrkfGK0a4cKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "\n",
        "y_pred = knn_model.predict(X_resampled)\n",
        "\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-mean:\", g_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSyeZMuczzOm",
        "outputId": "10c0e4eb-4fa5-4401-8298-c6557b28aced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9476614699331849\n",
            "Precision: 0.9068825910931174\n",
            "Recall: 0.9977728285077951\n",
            "G-mean: 0.3048114506844144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP**"
      ],
      "metadata": {
        "id": "oxq5jEjj4o7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "\n",
        "mlp_model = MLPClassifier(random_state=42)\n",
        "mlp_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred = mlp_model.predict(X_resampled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-mean:\", g_mean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHlEZdnD0DRm",
        "outputId": "69b39417-69cd-4af5-a49b-3a22976c4d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8485523385300668\n",
            "Precision: 0.832271762208068\n",
            "Recall: 0.8730512249443207\n",
            "G-mean: 0.3826687124158422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LR**"
      ],
      "metadata": {
        "id": "K-vPH4VH4m6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "lr_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "\n",
        "y_pred = lr_model.predict(X_resampled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-mean:\", g_mean)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5TtUqJt0bIG",
        "outputId": "7443c38e-fc81-4313-db78-626d899ac33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7405345211581291\n",
            "Precision: 0.6692789968652038\n",
            "Recall: 0.9510022271714922\n",
            "G-mean: 0.5608176268213948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NB**"
      ],
      "metadata": {
        "id": "J4kd1Rqf45R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "\n",
        "y_pred = nb_model.predict(X_resampled)\n",
        "\n",
        "accuracy = accuracy_score(y_resampled, y_pred)\n",
        "precision = precision_score(y_resampled, y_pred)\n",
        "recall = recall_score(y_resampled, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-mean:\", g_mean)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1rrFU5y0oaK",
        "outputId": "1cd241da-5069-447b-b2a1-b0d24c39a08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6414253897550112\n",
            "Precision: 0.5836627140974967\n",
            "Recall: 0.9866369710467706\n",
            "G-mean: 0.640916342978301\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoEYFrCDMmQfUMt1oTrohk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}