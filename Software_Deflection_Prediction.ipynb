{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOufg4JQj11UpPWiMUtdhZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritam-banik-roy/Software_Defect_Prediction/blob/main/Software_Deflection_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7frVJkG1ct1A",
        "outputId": "73f14094-a52a-4198-dc8a-5d6e5205ac42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Packages"
      ],
      "metadata": {
        "id": "ATo4c99TjJgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "45RZqzLldAUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/pc1.csv')\n"
      ],
      "metadata": {
        "id": "hP2h41VWjqf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_NxoBHKj2RG",
        "outputId": "5c3172db-4abc-4ed2-de53-0dbec2a97e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   McCabe's line count of code  McCabe \"cyclomatic complexity”  \\\n",
            "0                          1.1                             1.4   \n",
            "1                          1.0                             1.0   \n",
            "2                         91.0                             9.0   \n",
            "3                        109.0                            21.0   \n",
            "4                        505.0                           106.0   \n",
            "\n",
            "   McCabe \"essential complexity”  McCabe \"design complexity”  \\\n",
            "0                            1.4                         1.4   \n",
            "1                            1.0                         1.0   \n",
            "2                            3.0                         2.0   \n",
            "3                            5.0                        18.0   \n",
            "4                           41.0                        82.0   \n",
            "\n",
            "   Halstead total operators + operands  Halstead \"volume”  \\\n",
            "0                                  1.3               1.30   \n",
            "1                                  1.0               1.00   \n",
            "2                                318.0            2089.21   \n",
            "3                                381.0            2547.56   \n",
            "4                               2339.0           20696.93   \n",
            "\n",
            "   Halstead \"program length”  Halstead \"difficulty”  Halstead \"intelligence”  \\\n",
            "0                       1.30                   1.30                     1.30   \n",
            "1                       1.00                   1.00                     1.00   \n",
            "2                       0.04                  27.68                    75.47   \n",
            "3                       0.04                  28.37                    89.79   \n",
            "4                       0.01                  75.93                   272.58   \n",
            "\n",
            "   Halstead \"effort”  ...  Halstead's line count  \\\n",
            "0               1.30  ...                      2   \n",
            "1               1.00  ...                      1   \n",
            "2           57833.24  ...                     80   \n",
            "3           72282.68  ...                     97   \n",
            "4         1571506.88  ...                    457   \n",
            "\n",
            "   Halstead's count of lines of comments  Halstead's count of blank  \\\n",
            "0                                      2                          2   \n",
            "1                                      1                          1   \n",
            "2                                     44                         11   \n",
            "3                                     41                         12   \n",
            "4                                     71                         48   \n",
            "\n",
            "   lineslOCodeAndComment  unique operators  unique operands  total operators  \\\n",
            "0                      2               1.2              1.2              1.2   \n",
            "1                      1               1.0              1.0              1.0   \n",
            "2                     31              29.0             66.0            192.0   \n",
            "3                     24              28.0             75.0            229.0   \n",
            "4                     49              64.0            397.0           1397.0   \n",
            "\n",
            "   total operands  branchCount of the flow graph  defects  \n",
            "0             1.2                            1.4        0  \n",
            "1             1.0                            1.0        1  \n",
            "2           126.0                           17.0        1  \n",
            "3           152.0                           38.0        1  \n",
            "4           942.0                          178.0        1  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "McCabe's line count of code              0\n",
              "McCabe \"cyclomatic complexity”           0\n",
              "McCabe \"essential complexity”            0\n",
              "McCabe \"design complexity”               0\n",
              "Halstead total operators + operands      0\n",
              "Halstead \"volume”                        0\n",
              "Halstead \"program length”                0\n",
              "Halstead \"difficulty”                    0\n",
              "Halstead \"intelligence”                  0\n",
              "Halstead \"effort”                        0\n",
              "Halstead                                 0\n",
              "Halstead's time estimator                0\n",
              "Halstead's line count                    0\n",
              "Halstead's count of lines of comments    0\n",
              "Halstead's count of blank                0\n",
              "lineslOCodeAndComment                    0\n",
              "unique operators                         0\n",
              "unique operands                          0\n",
              "total operators                          0\n",
              "total operands                           0\n",
              "branchCount of the flow graph            0\n",
              "defects                                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling the dataset. Segementation into training and test set (80% - 20%) Normalizing the values"
      ],
      "metadata": {
        "id": "d2SlyjFzrEXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['defects'], axis =1).values\n",
        "\n",
        "y = df['defects'].values"
      ],
      "metadata": {
        "id": "8Mh3b26oVUyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=[0,1])\n",
        "\n",
        "train_X,test_X,train_Y,test_Y = train_test_split(X, y, test_size=0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "lweITR08k7-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras Model Definition"
      ],
      "metadata": {
        "id": "NO3v0MdwrQVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation,BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "uKEOOsj8k83e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "(Dense(32,activation = 'relu',input_shape = (21,))),\n",
        "(BatchNormalization()),\n",
        "(Dense(32,activation = 'relu')),\n",
        "(BatchNormalization()),\n",
        "(Dense(64,activation = 'relu')),\n",
        "(Dense(64,activation = 'relu')),\n",
        "(Dense(64,activation = 'relu')),\n",
        "(Dense(64,activation = 'relu')),\n",
        "(BatchNormalization()),\n",
        "(Dense(32,activation = 'relu')),\n",
        "(Dense(32,activation = 'relu')),\n",
        "(Dense(1,activation = 'linear',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "])\n",
        "ad = Adam(learning_rate = 0.0001)\n",
        "\n",
        "\n",
        "model.compile(optimizer = ad, loss='hinge',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "AfW7NunmlDJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=[0,1])\n",
        "\n",
        "train_X,test_X,train_Y,test_Y = train_test_split(X, y, test_size=0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "DqxvCqYklV7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "peDcPS6LrZ6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = train_X, y = train_Y,validation_data=(test_X,test_Y), batch_size = 64, epochs =200)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBxqivGlodl",
        "outputId": "f53743e7-74d3-4317-9d3b-10bf1d674371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "14/14 [==============================] - 5s 33ms/step - loss: 1.6975 - accuracy: 0.6381 - val_loss: 1.1464 - val_accuracy: 0.9234\n",
            "Epoch 2/200\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 1.5412 - accuracy: 0.7148 - val_loss: 1.1013 - val_accuracy: 0.9324\n",
            "Epoch 3/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1.3709 - accuracy: 0.8117 - val_loss: 1.0722 - val_accuracy: 0.9324\n",
            "Epoch 4/200\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 1.2557 - accuracy: 0.8410 - val_loss: 1.0470 - val_accuracy: 0.9324\n",
            "Epoch 5/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 1.1446 - accuracy: 0.8625 - val_loss: 1.0222 - val_accuracy: 0.9369\n",
            "Epoch 6/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 1.0680 - accuracy: 0.8625 - val_loss: 0.9949 - val_accuracy: 0.9369\n",
            "Epoch 7/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.9823 - accuracy: 0.8602 - val_loss: 0.9584 - val_accuracy: 0.9414\n",
            "Epoch 8/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.8833 - accuracy: 0.8692 - val_loss: 0.9258 - val_accuracy: 0.9459\n",
            "Epoch 9/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.7557 - accuracy: 0.8749 - val_loss: 0.8944 - val_accuracy: 0.9414\n",
            "Epoch 10/200\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.6597 - accuracy: 0.8805 - val_loss: 0.8568 - val_accuracy: 0.9414\n",
            "Epoch 11/200\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.8974 - val_loss: 0.8123 - val_accuracy: 0.9414\n",
            "Epoch 12/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.9087 - val_loss: 0.7675 - val_accuracy: 0.9414\n",
            "Epoch 13/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.9188 - val_loss: 0.7186 - val_accuracy: 0.9414\n",
            "Epoch 14/200\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2849 - accuracy: 0.9245 - val_loss: 0.6716 - val_accuracy: 0.9414\n",
            "Epoch 15/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2517 - accuracy: 0.9245 - val_loss: 0.6307 - val_accuracy: 0.9414\n",
            "Epoch 16/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.9245 - val_loss: 0.5817 - val_accuracy: 0.9459\n",
            "Epoch 17/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2460 - accuracy: 0.9233 - val_loss: 0.5545 - val_accuracy: 0.9459\n",
            "Epoch 18/200\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.2394 - accuracy: 0.9222 - val_loss: 0.5161 - val_accuracy: 0.9459\n",
            "Epoch 19/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2212 - accuracy: 0.9256 - val_loss: 0.4764 - val_accuracy: 0.9459\n",
            "Epoch 20/200\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.2209 - accuracy: 0.9233 - val_loss: 0.4431 - val_accuracy: 0.9459\n",
            "Epoch 21/200\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.2142 - accuracy: 0.9245 - val_loss: 0.4096 - val_accuracy: 0.9414\n",
            "Epoch 22/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.2138 - accuracy: 0.9211 - val_loss: 0.3814 - val_accuracy: 0.9414\n",
            "Epoch 23/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1984 - accuracy: 0.9256 - val_loss: 0.3553 - val_accuracy: 0.9459\n",
            "Epoch 24/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1928 - accuracy: 0.9256 - val_loss: 0.3289 - val_accuracy: 0.9459\n",
            "Epoch 25/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.2023 - accuracy: 0.9245 - val_loss: 0.3068 - val_accuracy: 0.9414\n",
            "Epoch 26/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1940 - accuracy: 0.9256 - val_loss: 0.2792 - val_accuracy: 0.9414\n",
            "Epoch 27/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1954 - accuracy: 0.9256 - val_loss: 0.2565 - val_accuracy: 0.9414\n",
            "Epoch 28/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.2012 - accuracy: 0.9267 - val_loss: 0.2384 - val_accuracy: 0.9414\n",
            "Epoch 29/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.2022 - accuracy: 0.9278 - val_loss: 0.2306 - val_accuracy: 0.9414\n",
            "Epoch 30/200\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.2021 - accuracy: 0.9267 - val_loss: 0.2250 - val_accuracy: 0.9414\n",
            "Epoch 31/200\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.1915 - accuracy: 0.9267 - val_loss: 0.2223 - val_accuracy: 0.9414\n",
            "Epoch 32/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1956 - accuracy: 0.9267 - val_loss: 0.2109 - val_accuracy: 0.9414\n",
            "Epoch 33/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1984 - accuracy: 0.9267 - val_loss: 0.2055 - val_accuracy: 0.9414\n",
            "Epoch 34/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1890 - accuracy: 0.9267 - val_loss: 0.2019 - val_accuracy: 0.9414\n",
            "Epoch 35/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1931 - accuracy: 0.9267 - val_loss: 0.1971 - val_accuracy: 0.9414\n",
            "Epoch 36/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1875 - accuracy: 0.9267 - val_loss: 0.1884 - val_accuracy: 0.9414\n",
            "Epoch 37/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1923 - accuracy: 0.9267 - val_loss: 0.1818 - val_accuracy: 0.9414\n",
            "Epoch 38/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1920 - accuracy: 0.9278 - val_loss: 0.1785 - val_accuracy: 0.9414\n",
            "Epoch 39/200\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.1877 - accuracy: 0.9278 - val_loss: 0.1728 - val_accuracy: 0.9414\n",
            "Epoch 40/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1928 - accuracy: 0.9256 - val_loss: 0.1690 - val_accuracy: 0.9414\n",
            "Epoch 41/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1844 - accuracy: 0.9278 - val_loss: 0.1663 - val_accuracy: 0.9414\n",
            "Epoch 42/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1832 - accuracy: 0.9278 - val_loss: 0.1670 - val_accuracy: 0.9414\n",
            "Epoch 43/200\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.1911 - accuracy: 0.9278 - val_loss: 0.1672 - val_accuracy: 0.9414\n",
            "Epoch 44/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1872 - accuracy: 0.9278 - val_loss: 0.1736 - val_accuracy: 0.9369\n",
            "Epoch 45/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1921 - accuracy: 0.9278 - val_loss: 0.1690 - val_accuracy: 0.9414\n",
            "Epoch 46/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1818 - accuracy: 0.9290 - val_loss: 0.1682 - val_accuracy: 0.9414\n",
            "Epoch 47/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1908 - accuracy: 0.9278 - val_loss: 0.1710 - val_accuracy: 0.9414\n",
            "Epoch 48/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1886 - accuracy: 0.9256 - val_loss: 0.1738 - val_accuracy: 0.9414\n",
            "Epoch 49/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1868 - accuracy: 0.9278 - val_loss: 0.1774 - val_accuracy: 0.9414\n",
            "Epoch 50/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1849 - accuracy: 0.9290 - val_loss: 0.1737 - val_accuracy: 0.9414\n",
            "Epoch 51/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1851 - accuracy: 0.9278 - val_loss: 0.1885 - val_accuracy: 0.9414\n",
            "Epoch 52/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1764 - accuracy: 0.9290 - val_loss: 0.1759 - val_accuracy: 0.9414\n",
            "Epoch 53/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1837 - accuracy: 0.9278 - val_loss: 0.1814 - val_accuracy: 0.9414\n",
            "Epoch 54/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1866 - accuracy: 0.9290 - val_loss: 0.1789 - val_accuracy: 0.9369\n",
            "Epoch 55/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1810 - accuracy: 0.9278 - val_loss: 0.1850 - val_accuracy: 0.9414\n",
            "Epoch 56/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1833 - accuracy: 0.9278 - val_loss: 0.1852 - val_accuracy: 0.9414\n",
            "Epoch 57/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1850 - accuracy: 0.9267 - val_loss: 0.1880 - val_accuracy: 0.9414\n",
            "Epoch 58/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1821 - accuracy: 0.9278 - val_loss: 0.1910 - val_accuracy: 0.9414\n",
            "Epoch 59/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1861 - accuracy: 0.9278 - val_loss: 0.1833 - val_accuracy: 0.9369\n",
            "Epoch 60/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1762 - accuracy: 0.9278 - val_loss: 0.1811 - val_accuracy: 0.9414\n",
            "Epoch 61/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1816 - accuracy: 0.9301 - val_loss: 0.1790 - val_accuracy: 0.9414\n",
            "Epoch 62/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1816 - accuracy: 0.9278 - val_loss: 0.1830 - val_accuracy: 0.9414\n",
            "Epoch 63/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1739 - accuracy: 0.9290 - val_loss: 0.1797 - val_accuracy: 0.9414\n",
            "Epoch 64/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1789 - accuracy: 0.9301 - val_loss: 0.1784 - val_accuracy: 0.9414\n",
            "Epoch 65/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1835 - accuracy: 0.9290 - val_loss: 0.1812 - val_accuracy: 0.9414\n",
            "Epoch 66/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1812 - accuracy: 0.9267 - val_loss: 0.1773 - val_accuracy: 0.9414\n",
            "Epoch 67/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1824 - accuracy: 0.9278 - val_loss: 0.1766 - val_accuracy: 0.9414\n",
            "Epoch 68/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1816 - accuracy: 0.9301 - val_loss: 0.1829 - val_accuracy: 0.9414\n",
            "Epoch 69/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1812 - accuracy: 0.9301 - val_loss: 0.1858 - val_accuracy: 0.9414\n",
            "Epoch 70/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1789 - accuracy: 0.9278 - val_loss: 0.1795 - val_accuracy: 0.9414\n",
            "Epoch 71/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1785 - accuracy: 0.9290 - val_loss: 0.1814 - val_accuracy: 0.9414\n",
            "Epoch 72/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1768 - accuracy: 0.9301 - val_loss: 0.1901 - val_accuracy: 0.9414\n",
            "Epoch 73/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1765 - accuracy: 0.9312 - val_loss: 0.1948 - val_accuracy: 0.9414\n",
            "Epoch 74/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1767 - accuracy: 0.9267 - val_loss: 0.1990 - val_accuracy: 0.9414\n",
            "Epoch 75/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1862 - accuracy: 0.9267 - val_loss: 0.2127 - val_accuracy: 0.9414\n",
            "Epoch 76/200\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.1741 - accuracy: 0.9335 - val_loss: 0.2037 - val_accuracy: 0.9414\n",
            "Epoch 77/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1833 - accuracy: 0.9267 - val_loss: 0.1832 - val_accuracy: 0.9414\n",
            "Epoch 78/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1747 - accuracy: 0.9312 - val_loss: 0.1835 - val_accuracy: 0.9414\n",
            "Epoch 79/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1810 - accuracy: 0.9290 - val_loss: 0.1745 - val_accuracy: 0.9414\n",
            "Epoch 80/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1808 - accuracy: 0.9256 - val_loss: 0.1744 - val_accuracy: 0.9414\n",
            "Epoch 81/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1821 - accuracy: 0.9278 - val_loss: 0.1810 - val_accuracy: 0.9414\n",
            "Epoch 82/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1763 - accuracy: 0.9290 - val_loss: 0.1821 - val_accuracy: 0.9414\n",
            "Epoch 83/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9267 - val_loss: 0.1738 - val_accuracy: 0.9414\n",
            "Epoch 84/200\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.1798 - accuracy: 0.9278 - val_loss: 0.1854 - val_accuracy: 0.9369\n",
            "Epoch 85/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1745 - accuracy: 0.9301 - val_loss: 0.2018 - val_accuracy: 0.9414\n",
            "Epoch 86/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1770 - accuracy: 0.9256 - val_loss: 0.1941 - val_accuracy: 0.9414\n",
            "Epoch 87/200\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.1773 - accuracy: 0.9256 - val_loss: 0.1852 - val_accuracy: 0.9414\n",
            "Epoch 88/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1853 - accuracy: 0.9267 - val_loss: 0.1870 - val_accuracy: 0.9414\n",
            "Epoch 89/200\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.1784 - accuracy: 0.9312 - val_loss: 0.1896 - val_accuracy: 0.9369\n",
            "Epoch 90/200\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.1756 - accuracy: 0.9312 - val_loss: 0.1833 - val_accuracy: 0.9369\n",
            "Epoch 91/200\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 0.1800 - accuracy: 0.9256 - val_loss: 0.1810 - val_accuracy: 0.9414\n",
            "Epoch 92/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1783 - accuracy: 0.9278 - val_loss: 0.1854 - val_accuracy: 0.9414\n",
            "Epoch 93/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1802 - accuracy: 0.9278 - val_loss: 0.1788 - val_accuracy: 0.9369\n",
            "Epoch 94/200\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 0.1770 - accuracy: 0.9267 - val_loss: 0.1835 - val_accuracy: 0.9414\n",
            "Epoch 95/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1800 - accuracy: 0.9267 - val_loss: 0.1822 - val_accuracy: 0.9369\n",
            "Epoch 96/200\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.1768 - accuracy: 0.9278 - val_loss: 0.1799 - val_accuracy: 0.9414\n",
            "Epoch 97/200\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 0.1754 - accuracy: 0.9301 - val_loss: 0.1877 - val_accuracy: 0.9414\n",
            "Epoch 98/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1759 - accuracy: 0.9267 - val_loss: 0.1840 - val_accuracy: 0.9369\n",
            "Epoch 99/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1750 - accuracy: 0.9278 - val_loss: 0.1898 - val_accuracy: 0.9414\n",
            "Epoch 100/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1775 - accuracy: 0.9290 - val_loss: 0.2031 - val_accuracy: 0.9414\n",
            "Epoch 101/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1828 - accuracy: 0.9290 - val_loss: 0.1890 - val_accuracy: 0.9369\n",
            "Epoch 102/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1788 - accuracy: 0.9267 - val_loss: 0.1996 - val_accuracy: 0.9414\n",
            "Epoch 103/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1710 - accuracy: 0.9301 - val_loss: 0.1913 - val_accuracy: 0.9414\n",
            "Epoch 104/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1839 - accuracy: 0.9256 - val_loss: 0.1902 - val_accuracy: 0.9414\n",
            "Epoch 105/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1802 - accuracy: 0.9267 - val_loss: 0.1840 - val_accuracy: 0.9414\n",
            "Epoch 106/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1752 - accuracy: 0.9301 - val_loss: 0.1805 - val_accuracy: 0.9369\n",
            "Epoch 107/200\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.1789 - accuracy: 0.9290 - val_loss: 0.1749 - val_accuracy: 0.9414\n",
            "Epoch 108/200\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.1743 - accuracy: 0.9267 - val_loss: 0.1763 - val_accuracy: 0.9414\n",
            "Epoch 109/200\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.1812 - accuracy: 0.9278 - val_loss: 0.1807 - val_accuracy: 0.9414\n",
            "Epoch 110/200\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.1763 - accuracy: 0.9278 - val_loss: 0.1774 - val_accuracy: 0.9414\n",
            "Epoch 111/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1758 - accuracy: 0.9290 - val_loss: 0.1833 - val_accuracy: 0.9414\n",
            "Epoch 112/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 0.1855 - val_accuracy: 0.9414\n",
            "Epoch 113/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1739 - accuracy: 0.9278 - val_loss: 0.1928 - val_accuracy: 0.9414\n",
            "Epoch 114/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1732 - accuracy: 0.9312 - val_loss: 0.1841 - val_accuracy: 0.9414\n",
            "Epoch 115/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1734 - accuracy: 0.9301 - val_loss: 0.1856 - val_accuracy: 0.9414\n",
            "Epoch 116/200\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.1772 - accuracy: 0.9256 - val_loss: 0.1870 - val_accuracy: 0.9414\n",
            "Epoch 117/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1734 - accuracy: 0.9278 - val_loss: 0.1815 - val_accuracy: 0.9414\n",
            "Epoch 118/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1755 - accuracy: 0.9301 - val_loss: 0.1796 - val_accuracy: 0.9414\n",
            "Epoch 119/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1783 - accuracy: 0.9278 - val_loss: 0.1995 - val_accuracy: 0.9414\n",
            "Epoch 120/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1780 - accuracy: 0.9267 - val_loss: 0.1865 - val_accuracy: 0.9414\n",
            "Epoch 121/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1795 - accuracy: 0.9278 - val_loss: 0.1872 - val_accuracy: 0.9414\n",
            "Epoch 122/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1746 - accuracy: 0.9278 - val_loss: 0.1960 - val_accuracy: 0.9414\n",
            "Epoch 123/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 0.1878 - val_accuracy: 0.9414\n",
            "Epoch 124/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1809 - accuracy: 0.9267 - val_loss: 0.1990 - val_accuracy: 0.9414\n",
            "Epoch 125/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1794 - accuracy: 0.9267 - val_loss: 0.1802 - val_accuracy: 0.9414\n",
            "Epoch 126/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1675 - accuracy: 0.9312 - val_loss: 0.1733 - val_accuracy: 0.9414\n",
            "Epoch 127/200\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1696 - accuracy: 0.9301 - val_loss: 0.1777 - val_accuracy: 0.9414\n",
            "Epoch 128/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1768 - accuracy: 0.9278 - val_loss: 0.1767 - val_accuracy: 0.9414\n",
            "Epoch 129/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1732 - accuracy: 0.9290 - val_loss: 0.1795 - val_accuracy: 0.9414\n",
            "Epoch 130/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1760 - accuracy: 0.9278 - val_loss: 0.1808 - val_accuracy: 0.9414\n",
            "Epoch 131/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1753 - accuracy: 0.9278 - val_loss: 0.1728 - val_accuracy: 0.9414\n",
            "Epoch 132/200\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.1714 - accuracy: 0.9290 - val_loss: 0.1722 - val_accuracy: 0.9414\n",
            "Epoch 133/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1714 - accuracy: 0.9278 - val_loss: 0.1719 - val_accuracy: 0.9414\n",
            "Epoch 134/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1708 - accuracy: 0.9278 - val_loss: 0.1723 - val_accuracy: 0.9369\n",
            "Epoch 135/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1799 - accuracy: 0.9278 - val_loss: 0.1748 - val_accuracy: 0.9414\n",
            "Epoch 136/200\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1754 - accuracy: 0.9290 - val_loss: 0.1767 - val_accuracy: 0.9369\n",
            "Epoch 137/200\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 0.1753 - accuracy: 0.9278 - val_loss: 0.1778 - val_accuracy: 0.9414\n",
            "Epoch 138/200\n",
            "14/14 [==============================] - 1s 39ms/step - loss: 0.1744 - accuracy: 0.9278 - val_loss: 0.1745 - val_accuracy: 0.9369\n",
            "Epoch 139/200\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.1695 - accuracy: 0.9324 - val_loss: 0.1839 - val_accuracy: 0.9414\n",
            "Epoch 140/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1750 - accuracy: 0.9278 - val_loss: 0.1728 - val_accuracy: 0.9414\n",
            "Epoch 141/200\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1687 - accuracy: 0.9290 - val_loss: 0.1812 - val_accuracy: 0.9414\n",
            "Epoch 142/200\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.1718 - accuracy: 0.9278 - val_loss: 0.1902 - val_accuracy: 0.9414\n",
            "Epoch 143/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1722 - accuracy: 0.9267 - val_loss: 0.1833 - val_accuracy: 0.9414\n",
            "Epoch 144/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1717 - accuracy: 0.9301 - val_loss: 0.1828 - val_accuracy: 0.9414\n",
            "Epoch 145/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1760 - accuracy: 0.9267 - val_loss: 0.1820 - val_accuracy: 0.9414\n",
            "Epoch 146/200\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.1744 - accuracy: 0.9267 - val_loss: 0.1903 - val_accuracy: 0.9414\n",
            "Epoch 147/200\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.1768 - accuracy: 0.9278 - val_loss: 0.1862 - val_accuracy: 0.9414\n",
            "Epoch 148/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1742 - accuracy: 0.9278 - val_loss: 0.1796 - val_accuracy: 0.9414\n",
            "Epoch 149/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1761 - accuracy: 0.9267 - val_loss: 0.1762 - val_accuracy: 0.9414\n",
            "Epoch 150/200\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.1750 - accuracy: 0.9278 - val_loss: 0.1697 - val_accuracy: 0.9369\n",
            "Epoch 151/200\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.1786 - accuracy: 0.9267 - val_loss: 0.1661 - val_accuracy: 0.9414\n",
            "Epoch 152/200\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.1762 - accuracy: 0.9278 - val_loss: 0.1696 - val_accuracy: 0.9369\n",
            "Epoch 153/200\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.1787 - accuracy: 0.9267 - val_loss: 0.1709 - val_accuracy: 0.9369\n",
            "Epoch 154/200\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1735 - accuracy: 0.9278 - val_loss: 0.1712 - val_accuracy: 0.9369\n",
            "Epoch 155/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1744 - accuracy: 0.9278 - val_loss: 0.1687 - val_accuracy: 0.9369\n",
            "Epoch 156/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 0.1777 - val_accuracy: 0.9414\n",
            "Epoch 157/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1782 - accuracy: 0.9278 - val_loss: 0.1853 - val_accuracy: 0.9414\n",
            "Epoch 158/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1714 - accuracy: 0.9278 - val_loss: 0.1938 - val_accuracy: 0.9414\n",
            "Epoch 159/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1753 - accuracy: 0.9278 - val_loss: 0.1847 - val_accuracy: 0.9414\n",
            "Epoch 160/200\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.1736 - accuracy: 0.9278 - val_loss: 0.1895 - val_accuracy: 0.9414\n",
            "Epoch 161/200\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1684 - accuracy: 0.9278 - val_loss: 0.1961 - val_accuracy: 0.9414\n",
            "Epoch 162/200\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.1753 - accuracy: 0.9278 - val_loss: 0.1942 - val_accuracy: 0.9414\n",
            "Epoch 163/200\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.1741 - accuracy: 0.9278 - val_loss: 0.1839 - val_accuracy: 0.9414\n",
            "Epoch 164/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1740 - accuracy: 0.9290 - val_loss: 0.1772 - val_accuracy: 0.9414\n",
            "Epoch 165/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1753 - accuracy: 0.9278 - val_loss: 0.1870 - val_accuracy: 0.9414\n",
            "Epoch 166/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1685 - accuracy: 0.9278 - val_loss: 0.1869 - val_accuracy: 0.9414\n",
            "Epoch 167/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1664 - accuracy: 0.9278 - val_loss: 0.1826 - val_accuracy: 0.9414\n",
            "Epoch 168/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 0.1783 - val_accuracy: 0.9414\n",
            "Epoch 169/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.9267 - val_loss: 0.1849 - val_accuracy: 0.9414\n",
            "Epoch 170/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1693 - accuracy: 0.9278 - val_loss: 0.1800 - val_accuracy: 0.9414\n",
            "Epoch 171/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1751 - accuracy: 0.9278 - val_loss: 0.1815 - val_accuracy: 0.9414\n",
            "Epoch 172/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1704 - accuracy: 0.9278 - val_loss: 0.1772 - val_accuracy: 0.9414\n",
            "Epoch 173/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1771 - accuracy: 0.9267 - val_loss: 0.1770 - val_accuracy: 0.9369\n",
            "Epoch 174/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.9278 - val_loss: 0.1796 - val_accuracy: 0.9369\n",
            "Epoch 175/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1705 - accuracy: 0.9278 - val_loss: 0.1763 - val_accuracy: 0.9414\n",
            "Epoch 176/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1744 - accuracy: 0.9278 - val_loss: 0.1751 - val_accuracy: 0.9414\n",
            "Epoch 177/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1711 - accuracy: 0.9290 - val_loss: 0.1780 - val_accuracy: 0.9369\n",
            "Epoch 178/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1704 - accuracy: 0.9267 - val_loss: 0.1820 - val_accuracy: 0.9369\n",
            "Epoch 179/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.9278 - val_loss: 0.1899 - val_accuracy: 0.9414\n",
            "Epoch 180/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1709 - accuracy: 0.9278 - val_loss: 0.1982 - val_accuracy: 0.9414\n",
            "Epoch 181/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1705 - accuracy: 0.9267 - val_loss: 0.1873 - val_accuracy: 0.9369\n",
            "Epoch 182/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.9267 - val_loss: 0.1877 - val_accuracy: 0.9414\n",
            "Epoch 183/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1632 - accuracy: 0.9301 - val_loss: 0.1918 - val_accuracy: 0.9414\n",
            "Epoch 184/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1684 - accuracy: 0.9290 - val_loss: 0.1941 - val_accuracy: 0.9414\n",
            "Epoch 185/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1706 - accuracy: 0.9278 - val_loss: 0.1952 - val_accuracy: 0.9414\n",
            "Epoch 186/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.9278 - val_loss: 0.2004 - val_accuracy: 0.9414\n",
            "Epoch 187/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1701 - accuracy: 0.9267 - val_loss: 0.1947 - val_accuracy: 0.9414\n",
            "Epoch 188/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1700 - accuracy: 0.9278 - val_loss: 0.1979 - val_accuracy: 0.9414\n",
            "Epoch 189/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9290 - val_loss: 0.1899 - val_accuracy: 0.9414\n",
            "Epoch 190/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1695 - accuracy: 0.9278 - val_loss: 0.2010 - val_accuracy: 0.9414\n",
            "Epoch 191/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1741 - accuracy: 0.9278 - val_loss: 0.1867 - val_accuracy: 0.9414\n",
            "Epoch 192/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.9267 - val_loss: 0.1877 - val_accuracy: 0.9414\n",
            "Epoch 193/200\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 0.9267 - val_loss: 0.1840 - val_accuracy: 0.9414\n",
            "Epoch 194/200\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.1684 - accuracy: 0.9278 - val_loss: 0.1892 - val_accuracy: 0.9414\n",
            "Epoch 195/200\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1724 - accuracy: 0.9290 - val_loss: 0.1854 - val_accuracy: 0.9414\n",
            "Epoch 196/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1689 - accuracy: 0.9267 - val_loss: 0.1904 - val_accuracy: 0.9414\n",
            "Epoch 197/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1733 - accuracy: 0.9256 - val_loss: 0.1835 - val_accuracy: 0.9414\n",
            "Epoch 198/200\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9301 - val_loss: 0.1819 - val_accuracy: 0.9414\n",
            "Epoch 199/200\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9290 - val_loss: 0.1849 - val_accuracy: 0.9369\n",
            "Epoch 200/200\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1698 - accuracy: 0.9267 - val_loss: 0.1907 - val_accuracy: 0.9414\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 32)                704       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,033\n",
            "Trainable params: 19,777\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_X)\n",
        "y_pred = (y_pred >= 0.65).astype(int).ravel()\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "\n",
        "svm_accuracy = accuracy_score(test_Y, y_pred)\n",
        "print('Accuracy (ANN +SVM): ', \"%.2f\" % (svm_accuracy*100))\n",
        "precision = precision_score(test_Y, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "recall = recall_score(test_Y, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "f1 = f1_score(test_Y, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "print('R2 Score:', roc_auc_score(test_Y,y_pred))\n"
      ],
      "metadata": {
        "id": "kZX0iRTWmUhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3910b139-dc06-4c1c-e9f8-6562698fdbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "Accuracy (ANN +SVM):  94.14\n",
            "Precision: 0.333333\n",
            "Recall: 0.083333\n",
            "F1 score: 0.133333\n",
            "R2 Score: 0.5369047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results"
      ],
      "metadata": {
        "id": "2Og_FcpYrlHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "fig = plt.pyplot.plot(figsize=(10,5))\n",
        "plt.pyplot.bar(test_Y,y_pred)\n",
        "\n",
        "plt.pyplot.plot(test_Y,test_Y,'r')\n",
        "\n"
      ],
      "metadata": {
        "id": "GEOHbZr8m0ov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "cd8772fe-7615-4f68-a636-3d35e769cbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe7a9b85750>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "y_pred = model.predict(test_X)\n",
        "y_pred = (y_pred >= 0.6).astype(int).ravel()\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(test_Y, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "precision = precision_score(test_Y, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "recall = recall_score(test_Y, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "f1 = f1_score(test_Y, y_pred)\n",
        "print('F1 score: %f' % f1)"
      ],
      "metadata": {
        "id": "RxZBqkR4nJM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3896f1b2-c2ca-4aa2-a142-1c27fbac28dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 6ms/step\n",
            "Accuracy: 0.941441\n",
            "Precision: 0.333333\n",
            "Recall: 0.083333\n",
            "F1 score: 0.133333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "ddnYdMCfnXt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision_Tree"
      ],
      "metadata": {
        "id": "wq6XQ7FmtdCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "df.defects=df['defects']*1\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_sm , y_sm = smote.fit_resample(X,y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_sm,y_sm,test_size=0.2,random_state=0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "SC = StandardScaler()\n",
        "X_train = SC.fit_transform(X_train)\n",
        "X_test = SC.transform(X_test)"
      ],
      "metadata": {
        "id": "S5ICQADYoDWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "8QQQWXabpu9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier(max_depth=3,criterion='entropy',random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OTqK9buKp4Ch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f6b19c09-f2a4-4502-efbb-30c37326ec57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
      ],
      "metadata": {
        "id": "_bP3vkBGqBQt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "0d37cd25-a535-4675-f51c-1cff75c986e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DT_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "_jhLwIuhqDAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "cm = confusion_matrix(y_test, DT_pred)\n",
        "cm"
      ],
      "metadata": {
        "id": "xkOXqgicqGws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78d7405-6ea3-4b31-8c43-135d85e72cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[158,  40],\n",
              "       [ 34, 181]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score:',accuracy_score(y_test,DT_pred))\n",
        "print('F1_score:',f1_score(y_test,DT_pred))\n",
        "print('precision_score:',precision_score(y_test,DT_pred))\n",
        "print('recall_score:',recall_score(y_test,DT_pred))"
      ],
      "metadata": {
        "id": "UXMDHYyjqM-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e7b347-9c9e-41ab-ce63-b0c79ceeb1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.8208232445520581\n",
            "F1_score: 0.8302752293577982\n",
            "precision_score: 0.8190045248868778\n",
            "recall_score: 0.8418604651162791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gussian_Naive_Bias"
      ],
      "metadata": {
        "id": "JvV9fiRutpXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "assgKU3htokb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b8e4365f-20e3-472f-aff9-3fad7ca44a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GaussianNB()"
      ],
      "metadata": {
        "id": "Y6eh3W6rvLHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "c0c91194-2aa2-4d44-f828-2fe562b757a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GNB_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "itgY6qKMvRXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "CM = confusion_matrix(y_test,GNB_pred)\n",
        "CM"
      ],
      "metadata": {
        "id": "tKIOjxt9vXOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a62853-eebb-4a3e-b39b-914bc2fd0880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[178,  20],\n",
              "       [141,  74]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score:',accuracy_score(y_test,GNB_pred))\n",
        "print('F1_score:',f1_score(y_test,GNB_pred))\n",
        "print('precision_score:',precision_score(y_test,GNB_pred))\n",
        "print('recall_score:',recall_score(y_test,GNB_pred))"
      ],
      "metadata": {
        "id": "L0s9-Urevb5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b398b5-c9ba-4d4d-bce0-d2cb81c63499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.6101694915254238\n",
            "F1_score: 0.4789644012944984\n",
            "precision_score: 0.7872340425531915\n",
            "recall_score: 0.34418604651162793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "Zp6o3MmZvzCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "KNN_pred = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "UBMAC_WivxM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "CM = confusion_matrix(y_test,KNN_pred)\n",
        "CM"
      ],
      "metadata": {
        "id": "Bh92EbqIxGiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c49065-901d-4427-8e6d-1c294cb02617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[182,  16],\n",
              "       [  7, 208]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score:',accuracy_score(y_test,KNN_pred))\n",
        "print('F1_score:',f1_score(y_test,KNN_pred))\n",
        "print('precision_score:',precision_score(y_test,KNN_pred))\n",
        "print('recall_score:',recall_score(y_test,KNN_pred))"
      ],
      "metadata": {
        "id": "CK-8GPDjxRoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aba8df3-9d77-452c-a7fc-2f6d63b2ccaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.9443099273607748\n",
            "F1_score: 0.9476082004555809\n",
            "precision_score: 0.9285714285714286\n",
            "recall_score: 0.9674418604651163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_rate = []\n",
        "\n",
        "for i in range(1,40):\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train,y_train)\n",
        "    pred_i = knn.predict(X_test)\n",
        "    error_rate.append(np.mean(pred_i != y_test))"
      ],
      "metadata": {
        "id": "bFkMX3sixiyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='red', markersize=10)\n",
        "plt.title('Error Rate vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error Rate')"
      ],
      "metadata": {
        "id": "XvK3wh2ixszW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "c8fa4f13-8efa-43dc-fe9a-a56ec0133a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Error Rate')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support_Vector_Classification"
      ],
      "metadata": {
        "id": "z5ZVhgH_yNBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_sm , y_sm = smote.fit_resample(X,y)"
      ],
      "metadata": {
        "id": "UywDOSjexycU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "z0XDVpKCyWRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b8634c80-1747-4a0f-84ba-234f71333bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear', random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SVC_pred= classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "rKonQ-8lynGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CM = confusion_matrix(y_test,SVC_pred)\n",
        "CM"
      ],
      "metadata": {
        "id": "7ziBWRTfysWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd55b913-fcbe-46b7-cca5-e83c6dc0b47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[155,  43],\n",
              "       [ 27, 188]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score:',accuracy_score(y_test,SVC_pred))\n",
        "print('F1_score:',f1_score(y_test,SVC_pred))\n",
        "print('precision_score:',precision_score(y_test,SVC_pred))\n",
        "print('recall_score:',recall_score(y_test,SVC_pred))"
      ],
      "metadata": {
        "id": "hG6c5fXPy3ON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4224d76b-aa09-42f8-e890-463fcbf8d682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.8305084745762712\n",
            "F1_score: 0.8430493273542601\n",
            "precision_score: 0.8138528138528138\n",
            "recall_score: 0.8744186046511628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SMOTE**"
      ],
      "metadata": {
        "id": "LNUqqAeCJZqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SVM***"
      ],
      "metadata": {
        "id": "6HknV6EdKnpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "#  Calculate accuracy, precision, and recall\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "v3GzhoEXJYmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d707ee-db06-4393-9570-975f99993ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7252252252252253\n",
            "Precision: 0.2\n",
            "Recall: 0.7368421052631579\n",
            "G-Mean: 0.7677718959499145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***DECISION*** TREE"
      ],
      "metadata": {
        "id": "V9LV84O9Jwi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = dt_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "T4BHYWrvKCTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c357c51-472f-4944-98ec-6b28de131377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8873873873873874\n",
            "Precision: 0.36363636363636365\n",
            "Recall: 0.42105263157894735\n",
            "G-Mean: 0.517631706652575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "yTpvHJvkKQTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "y0uJFi3NKPjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165bde87-228c-454e-894c-547770c8d267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8108108108108109\n",
            "Precision: 0.2553191489361702\n",
            "Recall: 0.631578947368421\n",
            "G-Mean: 0.6858022659924021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLP CLASSIFIER"
      ],
      "metadata": {
        "id": "sIxFQqwHLcw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "mlp_model = MLPClassifier()\n",
        "mlp_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "9L0s5cX3LfyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b0f9a3-afeb-4ff4-a0a5-e0590912ea8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8648648648648649\n",
            "Precision: 0.3225806451612903\n",
            "Recall: 0.5263157894736842\n",
            "G-Mean: 0.5971067765037417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "y72Rjw-bLozn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = lr_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "NzoTXhzuL7VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225feacc-cd98-4e5b-e750-00fab0536012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7522522522522522\n",
            "Precision: 0.20967741935483872\n",
            "Recall: 0.6842105263157895\n",
            "G-Mean: 0.73535503592651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GaussianNB"
      ],
      "metadata": {
        "id": "IqoxGbXJL_ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = nb_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "-3ZAVhaUMMJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6548f60-373d-4f38-f32e-09a784a0bdb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8468468468468469\n",
            "Precision: 0.2\n",
            "Recall: 0.2631578947368421\n",
            "G-Mean: 0.45883146774112354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ADASYN"
      ],
      "metadata": {
        "id": "UhDs7-FBPR6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "TfzxGvRwPgBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "XuTgDA82PU-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f161a1-7fa0-4fe3-e049-854dc03a514d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7792792792792793\n",
            "Precision: 0.23214285714285715\n",
            "Recall: 0.6842105263157895\n",
            "G-Mean: 0.7248282140270369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *DT*"
      ],
      "metadata": {
        "id": "UhudzdpIQJ6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = dt_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)"
      ],
      "metadata": {
        "id": "UE1FsY9CQL1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a549664a-bb74-4831-c76f-801993e7e7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8963963963963963\n",
            "Precision: 0.4090909090909091\n",
            "Recall: 0.47368421052631576\n",
            "G-Mean: 0.5290598323631228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***KNN***"
      ],
      "metadata": {
        "id": "sl-HcGzQQZs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "WoZLwnjXQ2iC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46e36e1-7c14-47f1-a75a-2e292ffb2931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7882882882882883\n",
            "Precision: 0.23076923076923078\n",
            "Recall: 0.631578947368421\n",
            "G-Mean: 0.6970150353573228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP**"
      ],
      "metadata": {
        "id": "blJ96kIGR69-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "mlp_model = MLPClassifier()\n",
        "mlp_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n",
        "\n"
      ],
      "metadata": {
        "id": "HZqFF7QvdH8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936fc8b1-3843-4bd0-ffd6-e9625d877305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8513513513513513\n",
            "Precision: 0.3055555555555556\n",
            "Recall: 0.5789473684210527\n",
            "G-Mean: 0.634071591877235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC **REGRESSION**"
      ],
      "metadata": {
        "id": "pMt7w-06dzjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "y_pred = lr_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "nY0Hn8khd2qd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff86113c-22ab-4b74-be73-406f4ab792c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8243243243243243\n",
            "Precision: 0.2916666666666667\n",
            "Recall: 0.7368421052631579\n",
            "G-Mean: 0.722447108487122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***GaussianNB***"
      ],
      "metadata": {
        "id": "0-9DNJcSeKlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_pred = nb_model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "KRbfmErTeK-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f0a3a5-64f1-4ead-8d51-7a34af90a6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8648648648648649\n",
            "Precision: 0.23809523809523808\n",
            "Recall: 0.2631578947368421\n",
            "G-Mean: 0.447773662839645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomOverSampler"
      ],
      "metadata": {
        "id": "c44U_U4ze7rG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM**"
      ],
      "metadata": {
        "id": "zVPtGITVe9i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "9UOiLRtLfAiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b515c6d9-7d4e-4466-ec47-f149ec81059e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7207207207207207\n",
            "Precision: 0.2054794520547945\n",
            "Recall: 0.7894736842105263\n",
            "G-Mean: 0.7919930960351028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DT"
      ],
      "metadata": {
        "id": "jvCvD6kpfcvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "BroaoZzogNsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e91247-dd91-42a5-a8e9-ec1e77182d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9099099099099099\n",
            "Precision: 0.47368421052631576\n",
            "Recall: 0.47368421052631576\n",
            "G-Mean: 0.49930699897395464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "7ObosByogVkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "qvqKz0-FgmBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54565c8e-7516-42cf-adab-bdfb7ee91a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8243243243243243\n",
            "Precision: 0.1875\n",
            "Recall: 0.3157894736842105\n",
            "G-Mean: 0.5065362251294778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MLP**"
      ],
      "metadata": {
        "id": "qGcmfgnXhGkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "mlp_model = MLPClassifier()\n",
        "mlp_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "eHHb9egQhJjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baff473-b727-4a79-bf64-5ac94b0c51c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1981981981981982\n",
            "Precision: 0.09644670050761421\n",
            "Recall: 1.0\n",
            "G-Mean: 0.9505542064987066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LR**"
      ],
      "metadata": {
        "id": "5PkqkBqwhqq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "y_pred = lr_model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "E98voBUehwMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9ed5fc-629e-44d9-f69f-d33df4700ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7927927927927928\n",
            "Precision: 0.2127659574468085\n",
            "Recall: 0.5263157894736842\n",
            "G-Mean: 0.6436875846301083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **NB**"
      ],
      "metadata": {
        "id": "A9trKnq_iGSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "g_mean = np.sqrt(recall * (1 - precision))\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"G-Mean:\", g_mean)\n"
      ],
      "metadata": {
        "id": "93kVcFITiH1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a18db4a-4534-458d-9ea3-fc6c890f8f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8738738738738738\n",
            "Precision: 0.2631578947368421\n",
            "Recall: 0.2631578947368421\n",
            "G-Mean: 0.44034738238635557\n"
          ]
        }
      ]
    }
  ]
}